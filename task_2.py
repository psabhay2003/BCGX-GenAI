# -*- coding: utf-8 -*-
"""Task 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10b-Sd_v11cyB-UdlEDvKmAc9uZpKPrkI
"""

#importing all the necessary libraries
import os
import pandas as pd
import re
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments, logging
import torch

#Disabling weights & biases logging
os.environ['WANDB_DISABLED'] = "true"
#Disabling Transformers advisory and info logs
os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = "true"
logging.set_verbosity_error()

#loading the dataset
df = pd.read_csv('https://raw.githubusercontent.com/psabhay2003/BCGX-GenAI/refs/heads/main/financial_chatbot_data.csv')
df

#Defining intent mapping based on keywords
intent_keywords = {
    'revenue': ['revenue'],
    'net_income': ['net income'],
    'assets': ['total assets'],
    'liabilities': ['total liabilities'],
    'operating_cashflow': ['operating cashflow'],
    'financing_cashflow': ['financing cashflow'],
    'investing_cashflow': ['investing cashflow'],
    'profit_margin': ['profit margin'],
    'gross_margin': ['gross margin'],
}

def assign_intent(question):
    q = question.lower() #lowercasing 'question' column so that it is not case-sensitive
    for intent, keywords in intent_keywords.items():
        for kw in keywords:
            if kw in q:
                return intent
    return 'other'

#Applying intent labels on dataframe
df['intent'] = df['question'].apply(assign_intent)
intents = sorted(df['intent'].unique()) #extracting all unique names from the new column, and sorting them alphabetically
label2id = {label: i for i, label in enumerate(intents)} #mapping each intent name to a unique integer index (0, 1, 2, â€¦)
id2label = {i: label for label, i in label2id.items()} #invert mapping
df['label'] = df['intent'].map(label2id)
df

#Train-test split
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])
#stratify ensures each label class appears in the train and test sets in roughly the same proportions as in the full dataset.

#Tokenization using BertTokenizer
tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=len(label2id), #how many label distinct intent classes are there
    id2label=id2label, #back and forth mapping as mentioned earlier
    label2id=label2id #back and forth mapping as mentioned earlier
)

#Dataset class
class QADataset(torch.utils.data.Dataset):
    def __init__(self, questions, labels, tokenizer):
        self.encodings = tokenizer(questions.tolist(), truncation=True, padding=True)
        self.labels = labels.tolist()

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = QADataset(train_df['question'], train_df['label'], tokenizer)
test_dataset = QADataset(test_df['question'], test_df['label'], tokenizer)

#Defining the training arguments
training_args = TrainingArguments( #this tells the hugging face trainer, how to run training
    output_dir='./results', #to define where to save model checkpoints and other outputs
    num_train_epochs=3, #epoch are the number of full passes over the training dataset.
    per_device_train_batch_size=8,#how many examples to process in each training batch per GPU
    per_device_eval_batch_size=8, #how many examples to process in each evaluation batch per GPU
    eval_strategy='epoch', #to run an evaluation pass at the end of every epoch
    save_strategy='epoch', #to save a model checkpoint at the end of every epoch.
    logging_dir='./logs', #to define directory where training logs (e.g. TensorBoard files) will be written
    logging_steps=10, #to emit a training log entry every 10 update steps
    load_best_model_at_end=True, #to automatically reload the checkpoint that performed best on the validation set
    metric_for_best_model='accuracy', #to set accuracy as the metric for best model
    report_to=[]  # disable all logging integrations, including wandb
)

#Defining a A callback function that the hugging face trainer will use to compute evaluation metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=1)
    return {'accuracy': accuracy_score(labels, preds)}

#Defining the trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics
)

#Training the model
trainer.train()

#Model Evaluation
eval_results = trainer.evaluate()
print("Evaluation results:\n", eval_results)
print("Classification report on test set:")
preds_output = trainer.predict(test_dataset)
preds = np.argmax(preds_output.predictions, axis=1)
print(classification_report(test_df['label'], preds, target_names=intents))

#Defining extraction & retrieval pipeline
class FinanceQA:
    def __init__(self, df, model, tokenizer, label2intent_map):
        self.df = df
        self.model = model
        self.tokenizer = tokenizer
        self.label2intent = label2intent_map
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        #Precompile regex
        self.pattern = re.compile(r"What (?:is|are) (?P<company>.+?)'s (?P<entity>.+?) in (?P<year>\d{4})\?")

    def predict_intent(self, question):
        inputs = self.tokenizer(question, return_tensors='pt', truncation=True, padding=True).to(self.device)
        outputs = self.model(**inputs)
        logits = outputs.logits.detach().cpu().numpy()
        intent_id = np.argmax(logits, axis=1)[0]
        return self.label2intent[intent_id]

    def extract_slots(self, question):
        match = self.pattern.match(question)
        if not match:
            raise ValueError("Could not extract slots from question: {}".format(question))
        return match.group('company'), match.group('entity'), match.group('year')

    def lookup(self, intent, company, year):
        intent_key = intent
        subset = self.df[
            (self.df['intent'] == intent_key) &
            (self.df['question'].str.contains(company, case=False)) &
            (self.df['question'].str.contains(year))
        ]
        if subset.empty:
            raise ValueError("No data found for {}, {}, {}".format(company, intent, year))
        return subset['response'].values[0]

    def answer(self, question):
        intent = self.predict_intent(question)
        company, entity, year = self.extract_slots(question)
        value = self.lookup(intent, company, year)
        return value

#Testing the pipeline
pipeline = FinanceQA(df, model, tokenizer, id2label)

sample_questions = [
    "What is Microsoft's operating cashflow in 2023?",
    "What is Apple's net income in 2024?",
]

for q in sample_questions:
    try:
        ans = pipeline.answer(q)
        print(f"Q: {q}\nA: {ans}\n")
    except Exception as e:
        print(f"Error for question '{q}': {e}")

#Deploying the model using Gradio for quick demo of chatbot
!pip install gradio
import gradio as gr

def gradio_answer_fn(question: str) -> str:
    try:
        return pipeline.answer(question)
    except Exception as e:
        return f"Error: {e}"

iface = gr.Interface(
    fn=gradio_answer_fn,
    inputs=gr.Textbox(lines=1, placeholder="e.g. What is Tesla's profit margin in 2024?"),
    outputs=gr.Textbox(label="Answer"),
    title="Finance Q&A Chatbot",
    description="Ask for revenue, profit margin, assets, liabilities, etc. in the format:\n"
                "`What is <Company>'s <Metric> in <Year>?`"
)

#Launching the UI
iface.launch(share=True)